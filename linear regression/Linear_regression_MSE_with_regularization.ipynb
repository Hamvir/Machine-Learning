{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QNglG5pJHBx0",
        "JrY5laPCHF6V",
        "Slx94l7FHhvv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# REGRESSION with SQUARED ERROR LOSS with different regularizations"
      ],
      "metadata": {
        "id": "QKrhs08G5cRI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oEPJYb3Yl_iJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "Q7kF3SRXdYRW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2flRuWupTJ8D",
        "outputId": "b9eba666-0437-4586-886b-72bfbdb1af05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "sHflviWK5nsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#below where the file is in gdrive, change with your respective location\n",
        "data_path = \"/content/drive/MyDrive/Colab Notebooks/PRNN_A1/Prnn_datasets/\"\n",
        "train_dataset = np.loadtxt(data_path + 'p1_train.csv', delimiter=',')\n",
        "test_dataset = np.loadtxt(data_path + 'p1_test.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "6Uf0IFTfnDeo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Last column is the target variable and rest are features\n",
        "features = train_dataset.shape[1]-1 #2"
      ],
      "metadata": {
        "id": "WuVZapKYOx0u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_dataset[:,0:features]\n",
        "Y_train = train_dataset[:,features]\n",
        "Y_train = Y_train.reshape(Y_train.shape[0],1)"
      ],
      "metadata": {
        "id": "ciT6NmANO3HQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_dataset[:,0:features]\n",
        "Y_test = test_dataset[:,features]\n",
        "Y_test = Y_test.reshape(Y_test.shape[0],1)"
      ],
      "metadata": {
        "id": "Uqdhad1zO3Kz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If variance of data is higher do normalize the data to bring it between 0 to 1 before passing it to the linear regression class"
      ],
      "metadata": {
        "id": "0b_zM6RG4lf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient descent with regularizer"
      ],
      "metadata": {
        "id": "XVf3pS7p60-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used here constant step size gradient descent , you can change the step size manually or can add variable step sizes in the code"
      ],
      "metadata": {
        "id": "GgAQUO4x9ZhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function with L2 regularizer\n",
        "#Training\n",
        "def L2_reg(self,X,Y):\n",
        "  epochs = self.epochs\n",
        "  epsilon = self.epsilon\n",
        "  alpha = self.alpha   \n",
        "  lmbda = self.lambd\n",
        "  tmp = np.ones((X.shape[0],1))\n",
        "  X=np.column_stack((X,tmp))  # Augmented data matrix\n",
        "  W_L2=np.ones((X.shape[1],1))\n",
        "  for i in range(epochs):\n",
        "    c = X@W_L2-Y\n",
        "    loss = np.linalg.norm(c)\n",
        "    MSE = loss*loss/X.shape[0]              # calculating loss\n",
        "    grad = X.T@(X@W_L2-Y) + lmbda * W_L2\n",
        "    W_L2 = W_L2 - alpha * grad/X.shape[0]       # Updating weights\n",
        "    if(i%2000==0):\n",
        "      print('Loss in ',i,' epoch is ',MSE)\n",
        "    if MSE<= epsilon:\n",
        "      break\n",
        "  self.W_L2 = W_L2\n"
      ],
      "metadata": {
        "id": "S7x97sDr7KlA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function with L1 regularizer\n",
        "#Training\n",
        "def L1_reg(self,X,Y):\n",
        "  epochs = self.epochs\n",
        "  epsilon = self.epsilon\n",
        "  alpha = self.alpha     \n",
        "  lmbda = self.lambd\n",
        "  tmp = np.ones((X.shape[0],1))\n",
        "  X=np.column_stack((X,tmp))  # Augmented data matrix\n",
        "  W_L1=np.ones((X.shape[1],1))\n",
        "  for i in range(epochs):\n",
        "    c = X@W_L1-Y\n",
        "    loss = np.linalg.norm(c)\n",
        "    MSE = loss*loss/X.shape[0]              # calculating loss\n",
        "    grad = X.T@(X@W_L1-Y) + lmbda * np.sign(W_L1)\n",
        "    W_L1 = W_L1 - alpha * grad/X.shape[0]       # Updating weights\n",
        "    if(i%2000==0):\n",
        "      print('Loss in ',i,' epoch is ',MSE)\n",
        "    if MSE<= epsilon:\n",
        "      break\n",
        "  self.W_L1 = W_L1"
      ],
      "metadata": {
        "id": "c0d5N4TEE3IY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function with L1 and L2 regularizer\n",
        "#Training\n",
        "def L1_L2_reg(self,X,Y):\n",
        "  epochs = self.epochs\n",
        "  epsilon = self.epsilon\n",
        "  alpha = self.alpha     \n",
        "  lmbda = self.lambd\n",
        "  tmp = np.ones((X.shape[0],1))\n",
        "  X=np.column_stack((X,tmp))  # Augmented data matrix\n",
        "  W_L1_L2=np.ones((X.shape[1],1))\n",
        "  for i in range(epochs):\n",
        "    c = X@W_L1_L2-Y\n",
        "    loss = np.linalg.norm(c)\n",
        "    MSE = loss*loss/X.shape[0]              # calculating loss\n",
        "    grad = X.T@(X@W_L1_L2-Y) + lmbda * np.sign(W_L1_L2) + lmbda * W_L1_L2\n",
        "    W_L1_L2 = W_L1_L2 - alpha * grad/X.shape[0]       # Updating weights\n",
        "    if(i%2000==0):\n",
        "      print('Loss in ',i,' epoch is ',MSE)\n",
        "    if MSE<= epsilon:\n",
        "      break\n",
        "  self.W_L1_L2 = W_L1_L2"
      ],
      "metadata": {
        "id": "V5UXrCq3Hm0t"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_regression:\n",
        "  def __init__(self,alpha = 0.01,epochs=15000,epsilon=0.01,lambd=1):\n",
        "    self.epochs = epochs\n",
        "    self.alpha = alpha\n",
        "    self.epsilon = epsilon\n",
        "    self.lambd = lambd\n",
        "  train_L1 = L1_reg\n",
        "  train_L2 = L2_reg\n",
        "  train_L1_L2 = L1_L2_reg\n",
        "  def test_L2(self,X,Y):     # call this function to return mean squared error on test dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W_L2\n",
        "    loss =(np.linalg.norm(y_pred-Y))**2\n",
        "    MSE = loss/X.shape[0]\n",
        "    return(MSE)\n",
        "\n",
        "  def test_L1(self,X,Y):     # call this function to return mean squared error on test dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W_L1\n",
        "    loss =(np.linalg.norm(y_pred-Y))**2\n",
        "    MSE = loss/X.shape[0]\n",
        "    return(MSE)\n",
        "\n",
        "  def test_L1_L2(self,X,Y):     # call this function to return mean squared error on test dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W_L1_L2\n",
        "    loss =(np.linalg.norm(y_pred-Y))**2\n",
        "    MSE = loss/X.shape[0]\n",
        "    return(MSE)\n",
        "\n",
        "\n",
        "  \n",
        "  def predict_L2(self,X):    # call this function to predict value and return predicted value on a dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W_L2\n",
        "    return(Y_pred)\n",
        "\n",
        "  def predict_L1(self,X):    # call this function to predict value and return predicted value on a dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W_L1\n",
        "    return(Y_pred)\n",
        "\n",
        "  def predict_L1_L2(self,X):    # call this function to predict value and return predicted value on a dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W_L1_L2\n",
        "    return(Y_pred)"
      ],
      "metadata": {
        "id": "keIn7k_K66Rw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L2 regression"
      ],
      "metadata": {
        "id": "QNglG5pJHBx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = Linear_regression() "
      ],
      "metadata": {
        "id": "gxMBBHWw2NqP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.train_L2(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzfyxdrg2NqR",
        "outputId": "c6d20b79-af42-4059-eb50-b97ca9ee4d32"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss in  0  epoch is  1731.5804704188197\n",
            "Loss in  2000  epoch is  5.059684704703455\n",
            "Loss in  4000  epoch is  5.059684704701259\n",
            "Loss in  6000  epoch is  5.059684704701259\n",
            "Loss in  8000  epoch is  5.059684704701259\n",
            "Loss in  10000  epoch is  5.059684704701259\n",
            "Loss in  12000  epoch is  5.059684704701259\n",
            "Loss in  14000  epoch is  5.059684704701259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = l.predict_L2(X_test)"
      ],
      "metadata": {
        "id": "0xCJ3iB32NqS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = l.test_L2(X_test,Y_test)"
      ],
      "metadata": {
        "id": "t9XpR9Dt2NqS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Mean squared error loss is: ',mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dcf9070-5936-472f-eec4-d1b34fdb5250",
        "id": "7ZQNtIJt2NqS"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean squared error loss is:  5.046471860188153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L1 regression"
      ],
      "metadata": {
        "id": "JrY5laPCHF6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = Linear_regression() "
      ],
      "metadata": {
        "id": "i9ZHnh4qHKIW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.train_L1(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd90acd-7c45-4999-ffc5-4a7d869a6139",
        "id": "DYKJvRD8HKIX"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss in  0  epoch is  1731.5804704188197\n",
            "Loss in  2000  epoch is  5.05968462579587\n",
            "Loss in  4000  epoch is  5.059684625795129\n",
            "Loss in  6000  epoch is  5.059684625795129\n",
            "Loss in  8000  epoch is  5.059684625795129\n",
            "Loss in  10000  epoch is  5.059684625795129\n",
            "Loss in  12000  epoch is  5.059684625795129\n",
            "Loss in  14000  epoch is  5.059684625795129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = l.predict_L1(X_test)"
      ],
      "metadata": {
        "id": "mFwAG0mwHKIY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = l.test_L1(X_test,Y_test)"
      ],
      "metadata": {
        "id": "MRM44rp4HKIY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Mean squared error loss is: ',mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a79427-1c09-41a1-e08c-69a44d6ce621",
        "id": "kHYds_kTHKIZ"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean squared error loss is:  5.046448458668469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Both L1 and L2 regression"
      ],
      "metadata": {
        "id": "Slx94l7FHhvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = Linear_regression() "
      ],
      "metadata": {
        "id": "NdgqJFrSIEhn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.train_L1_L2(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d828541-fb48-41a0-e23d-b61c02101006",
        "id": "btK9YPIRIEho"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss in  0  epoch is  1731.5804704188197\n",
            "Loss in  2000  epoch is  5.0596847748593845\n",
            "Loss in  4000  epoch is  5.059684774856448\n",
            "Loss in  6000  epoch is  5.059684774856448\n",
            "Loss in  8000  epoch is  5.059684774856448\n",
            "Loss in  10000  epoch is  5.059684774856448\n",
            "Loss in  12000  epoch is  5.059684774856448\n",
            "Loss in  14000  epoch is  5.059684774856448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = l.predict_L1_L2(X_test)"
      ],
      "metadata": {
        "id": "SnQQDXrnIEho"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = l.test_L1_L2(X_test,Y_test)"
      ],
      "metadata": {
        "id": "Dc5Tqf6eIEho"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Mean squared error loss is: ',mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e8e86e-f975-4e5f-a9cf-99312928ceef",
        "id": "THdXYssbIEhp"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean squared error loss is:  5.046484373624463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "62WCx7BCIOls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}