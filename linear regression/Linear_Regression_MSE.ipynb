{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# REGRESSION with SQUARED ERROR LOSS"
      ],
      "metadata": {
        "id": "VFWCqTyvZfwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is just an example to show how to use the \"linear_regression\" class or \"linear_regression_gd\" class"
      ],
      "metadata": {
        "id": "xmMURWOl411W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oEPJYb3Yl_iJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "Q7kF3SRXdYRW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2flRuWupTJ8D",
        "outputId": "e1fae8ed-65e4-4725-fdaa-806049f5925f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "BslpafmwTj92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#below where the file is in gdrive, change with your respective location\n",
        "data_path = \"/content/drive/MyDrive/Colab Notebooks/PRNN_A1/Prnn_datasets/\"\n",
        "train_dataset = np.loadtxt(data_path + 'p1_train.csv', delimiter=',')\n",
        "test_dataset = np.loadtxt(data_path + 'p1_test.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "6Uf0IFTfnDeo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Last column is the target variable and rest are features\n",
        "features = train_dataset.shape[1]-1 #2"
      ],
      "metadata": {
        "id": "WuVZapKYOx0u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_dataset[:,0:features]\n",
        "Y_train = train_dataset[:,features]\n",
        "Y_train = Y_train.reshape(Y_train.shape[0],1)"
      ],
      "metadata": {
        "id": "ciT6NmANO3HQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_dataset[:,0:features]\n",
        "Y_test = test_dataset[:,features]\n",
        "Y_test = Y_test.reshape(Y_test.shape[0],1)"
      ],
      "metadata": {
        "id": "Uqdhad1zO3Kz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If variance of data is higher do normalize the data to bring it between 0 to 1 before passing it to the linear regression class"
      ],
      "metadata": {
        "id": "0b_zM6RG4lf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding using formulae"
      ],
      "metadata": {
        "id": "wwh8yDLYUoVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following class is class of linear regression you can create an object of the class for your needs.\n",
        "Here we are assuming the matrix (A.T@A) is invertible"
      ],
      "metadata": {
        "id": "LVPdiDBjYxD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_regression:\n",
        "  def train(self,X,Y):    # First call this function to update W value\n",
        "    # Creating augmented data matrix\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    self.W = (np.linalg.inv(X.T@X))@X.T@Y\n",
        "  def test(self,X,Y):     # call this function to return mean squared error on test dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W\n",
        "    loss =(np.linalg.norm(y_pred-Y))**2\n",
        "    MSE = loss/X.shape[0]\n",
        "    return(MSE)\n",
        "  def predict(self,X):    # call this function to predict value and return predicted value on a dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W\n",
        "    return(Y_pred)"
      ],
      "metadata": {
        "id": "A28mACUNUeVy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = Linear_regression() "
      ],
      "metadata": {
        "id": "YCzm7n0nXEi_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.train(X_train,Y_train)"
      ],
      "metadata": {
        "id": "wg-Do879XKtD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = l.predict(X_test)"
      ],
      "metadata": {
        "id": "XTSHHrcRXPjk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = l.test(X_test,Y_test)"
      ],
      "metadata": {
        "id": "N3dkX95kXgkl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Mean squared error loss is: ',mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrvhtAE6Yeqc",
        "outputId": "980d6ea4-036b-4f1f-aab2-b8a43cf7609c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean squared error loss is:  5.046436003951254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Gradient Descent"
      ],
      "metadata": {
        "id": "WT-NfBSdY1kx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the gradient descent function, with parameters like epochs,epsilon aand alpha, you can play with it according to your needs."
      ],
      "metadata": {
        "id": "O_1JOjmOvB2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is written with a variable alpha you can replace it with your form of changing alpha or gradient descent like adam or adaboost."
      ],
      "metadata": {
        "id": "TN7qAt_Lv2qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_descent(self,X,Y):\n",
        "  epochs = 15000\n",
        "  prev_MSE = 0\n",
        "  epsilon = 0.001\n",
        "  alpha = 10                  # selected after a lot of experiment with different values\n",
        "  tmp = np.ones((X.shape[0],1))\n",
        "  X=np.column_stack((X,tmp))  # Augmented data matrix\n",
        "  W=np.ones((X.shape[1],1))\n",
        "  for i in range(epochs):\n",
        "    c = X@W-Y\n",
        "    loss = np.linalg.norm(c)\n",
        "    MSE = loss*loss/X.shape[0]              # calculating loss\n",
        "    grad = X.T@(X@W-Y)\n",
        "    if prev_MSE<MSE:\n",
        "      alpha = (alpha/10)\n",
        "    W = W - alpha * grad/np.linalg.norm(grad)       # Updating weights\n",
        "    prev_MSE = MSE\n",
        "    if(i%2000==0):\n",
        "      print('Loss in ',i,' epoch is ',MSE)\n",
        "    if MSE<= epsilon:\n",
        "      break\n",
        "  print('Final loss is',prev_MSE)\n",
        "  self.W = W\n"
      ],
      "metadata": {
        "id": "sU0hRTxTuv9F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also add more feature (linear or non linear) to your dataset and give it to linear regression class to predict y value.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cEBhKDMT2v9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_regression_GD:\n",
        "  train = grad_descent\n",
        "  def test(self,X,Y):     # call this function to return mean squared error on test dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W\n",
        "    loss =(np.linalg.norm(y_pred-Y))**2\n",
        "    MSE = loss/X.shape[0]\n",
        "    return(MSE)\n",
        "  def predict(self,X):    # call this function to predict value and return predicted value on a dataset\n",
        "    tmp = np.ones((X.shape[0],1))\n",
        "    X=np.column_stack((X,tmp))\n",
        "    Y_pred = X@self.W\n",
        "    return(Y_pred)"
      ],
      "metadata": {
        "id": "2zp0ENbbY4ip"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = Linear_regression_GD() "
      ],
      "metadata": {
        "id": "gxMBBHWw2NqP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.train(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzfyxdrg2NqR",
        "outputId": "28e52b1b-c483-48b1-a397-8f33a1ce6536"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss in  0  epoch is  1731.5804704188197\n",
            "Loss in  2000  epoch is  5.059684615643722\n",
            "Loss in  4000  epoch is  5.059684615643722\n",
            "Loss in  6000  epoch is  5.059684615643722\n",
            "Loss in  8000  epoch is  5.059684615643722\n",
            "Loss in  10000  epoch is  5.059684615643722\n",
            "Loss in  12000  epoch is  5.059684615643722\n",
            "Loss in  14000  epoch is  5.059684615643722\n",
            "Final loss is 5.059684615643722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = l.predict(X_test)"
      ],
      "metadata": {
        "id": "0xCJ3iB32NqS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = l.test(X_test,Y_test)"
      ],
      "metadata": {
        "id": "t9XpR9Dt2NqS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Mean squared error loss is: ',mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7296f889-79a5-46ba-de8e-f72e76e40176",
        "id": "7ZQNtIJt2NqS"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean squared error loss is:  5.046435996689454\n"
          ]
        }
      ]
    }
  ]
}